{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from fastai.gen_doc.nbdoc import *\n",
    "from fastai.text import * \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main thing here is [`RNNLearner`](/text.learner.html#RNNLearner). There are also some utility functions to help create and update text models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickly get a learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"language_model_learner\" class=\"doc_header\"><code>language_model_learner</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L201\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#language_model_learner-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>language_model_learner</code>(**`data`**:[`DataBunch`](/basic_data.html#DataBunch), **`arch`**, **`config`**:`dict`=***`None`***, **`drop_mult`**:`float`=***`1.0`***, **`pretrained`**:`bool`=***`True`***, **`pretrained_fnames`**:`OptStrTuple`=***`None`***, **\\*\\*`learn_kwargs`**) → `LanguageLearner`\n",
       "\n",
       "<div class=\"collapse\" id=\"language_model_learner-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#language_model_learner-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>Tests found for <code>language_model_learner</code>:</p><ul><li><code>pytest -sv tests/test_text_train.py::test_qrnn_works_if_split_fn_provided</code> <a href=\"https://github.com/fastai/fastai/blob/master/tests/test_text_train.py#L73\" class=\"source_link\" style=\"float:right\">[source]</a></li><li><code>pytest -sv tests/test_text_train.py::test_qrnn_works_with_no_split</code> <a href=\"https://github.com/fastai/fastai/blob/master/tests/test_text_train.py#L61\" class=\"source_link\" style=\"float:right\">[source]</a></li></ul><p>To run tests please refer to this <a href=\"/dev/test.html#quick-guide\">guide</a>.</p></div></div>\n",
       "\n",
       "Create a [`Learner`](/basic_train.html#Learner) with a language model from `data` and `arch`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(language_model_learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model used is given by `arch` and `config`. It can be:\n",
    "\n",
    "- an [<code>AWD_LSTM</code>](/text.models.html#AWD_LSTM)([Merity et al.](https://arxiv.org/abs/1708.02182))\n",
    "- a [<code>Transformer</code>](/text.models.html#Transformer) decoder ([Vaswani et al.](https://arxiv.org/abs/1706.03762))\n",
    "- a [<code>TransformerXL</code>](/text.models.html#TransformerXL) ([Dai et al.](https://arxiv.org/abs/1901.02860))\n",
    "\n",
    "They each have a default config for language modelling that is in <code>{lower_case_class_name}_lm_config</code> if you want to change the default parameter. At this stage, only the AWD LSTM support `pretrained=True` but we hope to add more pretrained models soon. `drop_mult` is applied to all the dropouts weights of the `config`, `learn_kwargs` are passed to the [`Learner`](/basic_train.html#Learner) initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div markdown=\"span\" class=\"alert alert-info\" role=\"alert\"><i class=\"fa fa-info-circle\"></i> <b>Note: </b>Using QRNN (change the flag in the config of the AWD LSTM) requires to have cuda installed (same version as pytorch is using).</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jekyll_note(\"Using QRNN (change the flag in the config of the AWD LSTM) requires to have cuda installed (same version as pytorch is using).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "data = TextLMDataBunch.from_csv(path, 'texts.csv')\n",
    "learn = language_model_learner(data, AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"text_classifier_learner\" class=\"doc_header\"><code>text_classifier_learner</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L286\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#text_classifier_learner-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>text_classifier_learner</code>(**`data`**:[`DataBunch`](/basic_data.html#DataBunch), **`arch`**:`Callable`, **`bptt`**:`int`=***`70`***, **`max_len`**:`int`=***`1400`***, **`config`**:`dict`=***`None`***, **`pretrained`**:`bool`=***`True`***, **`drop_mult`**:`float`=***`1.0`***, **`lin_ftrs`**:`Collection`\\[`int`\\]=***`None`***, **`ps`**:`Collection`\\[`float`\\]=***`None`***, **\\*\\*`learn_kwargs`**) → `TextClassifierLearner`\n",
       "\n",
       "<div class=\"collapse\" id=\"text_classifier_learner-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#text_classifier_learner-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>Tests found for <code>text_classifier_learner</code>:</p><ul><li><code>pytest -sv tests/test_text_train.py::test_classifier</code> <a href=\"https://github.com/fastai/fastai/blob/master/tests/test_text_train.py#L100\" class=\"source_link\" style=\"float:right\">[source]</a></li><li><code>pytest -sv tests/test_text_train.py::test_order_preds</code> <a href=\"https://github.com/fastai/fastai/blob/master/tests/test_text_train.py#L139\" class=\"source_link\" style=\"float:right\">[source]</a></li></ul><p>To run tests please refer to this <a href=\"/dev/test.html#quick-guide\">guide</a>.</p></div></div>\n",
       "\n",
       "Create a [`Learner`](/basic_train.html#Learner) with a text classifier from `data` and `arch`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(text_classifier_learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here again, the backbone of the model is determined by `arch` and `config`. The input texts are fed into that model by bunch of `bptt` and only the last `max_len` activations are considered. This gives us the backbone of our model. The head then consists of:\n",
    "- a layer that concatenates the final outputs of the RNN with the maximum and average of all the intermediate outputs (on the sequence length dimension),\n",
    "- blocks of ([`nn.BatchNorm1d`](https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm1d), [`nn.Dropout`](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout), [`nn.Linear`](https://pytorch.org/docs/stable/nn.html#torch.nn.Linear), [`nn.ReLU`](https://pytorch.org/docs/stable/nn.html#torch.nn.ReLU)) layers.\n",
    "\n",
    "The blocks are defined by the `lin_ftrs` and `drops` arguments. Specifically, the first block will have a number of inputs inferred from the backbone arch and the last one will have a number of outputs equal to data.c (which contains the number of classes of the data) and the intermediate blocks have a number of inputs/outputs determined by `lin_ftrs` (of course a block has a number of inputs equal to the number of outputs of the previous block). The dropouts all have a the same value ps if you pass a float, or the corresponding values if you pass a list. Default is to have an intermediate hidden size of 50 (which makes two blocks model_activation -> 50 -> n_classes) with a dropout of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "data = TextClasDataBunch.from_csv(path, 'texts.csv')\n",
    "learn = text_classifier_learner(data, AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"RNNLearner\" class=\"doc_header\"><code>class</code> <code>RNNLearner</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L45\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#RNNLearner-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h2>\n",
       "\n",
       "> <code>RNNLearner</code>(**`data`**:[`DataBunch`](/basic_data.html#DataBunch), **`model`**:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), **`split_func`**:`OptSplitFunc`=***`None`***, **`clip`**:`float`=***`None`***, **`alpha`**:`float`=***`2.0`***, **`beta`**:`float`=***`1.0`***, **`metrics`**=***`None`***, **\\*\\*`learn_kwargs`**) :: [`Learner`](/basic_train.html#Learner)\n",
       "\n",
       "<div class=\"collapse\" id=\"RNNLearner-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#RNNLearner-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>RNNLearner</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Basic class for a [`Learner`](/basic_train.html#Learner) in NLP.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(RNNLearner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handles the whole creation from <code>data</code> and a `model` with a text data using a certain `bptt`. The `split_func` is used to properly split the model in different groups for gradual unfreezing and differential learning rates. Gradient clipping of `clip` is optionally applied. `alpha` and `beta` are all passed to create an instance of [`RNNTrainer`](/callbacks.rnn.html#RNNTrainer). Can be used for a language model or an RNN classifier. It also handles the conversion of weights from a pretrained model as well as saving or loading the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"RNNLearner.get_preds\" class=\"doc_header\"><code>get_preds</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L81\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#RNNLearner-get_preds-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>get_preds</code>(**`ds_type`**:[`DatasetType`](/basic_data.html#DatasetType)=***`<DatasetType.Valid: 2>`***, **`with_loss`**:`bool`=***`False`***, **`n_batch`**:`Optional`\\[`int`\\]=***`None`***, **`pbar`**:`Union`\\[`MasterBar`, `ProgressBar`, `NoneType`\\]=***`None`***, **`ordered`**:`bool`=***`False`***) → `List`\\[`Tensor`\\]\n",
       "\n",
       "<div class=\"collapse\" id=\"RNNLearner-get_preds-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#RNNLearner-get_preds-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>get_preds</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Return predictions and targets on the valid, train, or test set, depending on `ds_type`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(RNNLearner.get_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `ordered=True`, returns the predictions in the order of the dataset, otherwise they will be ordered by the sampler (from the longest text to the shortest). The other arguments are passed [`Learner.get_preds`](/basic_train.html#Learner.get_preds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TextClassificationInterpretation\" class=\"doc_header\"><code>class</code> <code>TextClassificationInterpretation</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L206\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#TextClassificationInterpretation-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n",
       "\n",
       "> <code>TextClassificationInterpretation</code>(**`data`**:[`TextClasDataBunch`](/text.data.html#TextClasDataBunch), **`model`**:[`AWD_LSTM`](/text.models.awd_lstm.html#AWD_LSTM))\n",
       "\n",
       "<div class=\"collapse\" id=\"TextClassificationInterpretation-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#TextClassificationInterpretation-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>TextClassificationInterpretation</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Provides an interpretation of classification based on input sensitivity. This was designed for AWD-LSTM only for the moment, because Transformer already has its own attentional model. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextClassificationInterpretation,title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The darker the word-shading in the below example, the more it contributes to the classification.  Results here are without any fitting.  After fitting to acceptable accuracy, this class can show you what is being used to produce the classification of a particular case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.425\" style=\"background-color: rgba(176, 175, 212, 0.5);\">xxbos</span> <span title=\"0.156\" style=\"background-color: rgba(234, 232, 242, 0.5);\">xxmaj</span> <span title=\"0.089\" style=\"background-color: rgba(243, 241, 247, 0.5);\">here</span> <span title=\"0.055\" style=\"background-color: rgba(246, 245, 249, 0.5);\">i</span> <span title=\"0.047\" style=\"background-color: rgba(247, 245, 249, 0.5);\">thought</span> <span title=\"0.047\" style=\"background-color: rgba(247, 245, 249, 0.5);\">&quot;</span> <span title=\"0.057\" style=\"background-color: rgba(246, 244, 249, 0.5);\">xxmaj</span> <span title=\"0.073\" style=\"background-color: rgba(244, 243, 248, 0.5);\">xxunk</span> <span title=\"0.089\" style=\"background-color: rgba(243, 241, 247, 0.5);\">of</span> <span title=\"0.100\" style=\"background-color: rgba(241, 240, 246, 0.5);\">the</span> <span title=\"0.097\" style=\"background-color: rgba(242, 240, 246, 0.5);\">north</span> <span title=\"0.068\" style=\"background-color: rgba(245, 243, 248, 0.5);\">&quot;</span> <span title=\"0.038\" style=\"background-color: rgba(248, 247, 250, 0.5);\">was</span> <span title=\"0.046\" style=\"background-color: rgba(247, 246, 250, 0.5);\">the</span> <span title=\"0.054\" style=\"background-color: rgba(246, 245, 249, 0.5);\">last</span> <span title=\"0.061\" style=\"background-color: rgba(245, 244, 249, 0.5);\">word</span> <span title=\"0.066\" style=\"background-color: rgba(245, 243, 248, 0.5);\">in</span> <span title=\"0.072\" style=\"background-color: rgba(244, 243, 248, 0.5);\">archaic</span> <span title=\"0.086\" style=\"background-color: rgba(243, 241, 247, 0.5);\">semi</span> <span title=\"0.110\" style=\"background-color: rgba(240, 238, 245, 0.5);\">-</span> <span title=\"0.138\" style=\"background-color: rgba(236, 235, 244, 0.5);\">doc</span> <span title=\"0.166\" style=\"background-color: rgba(232, 230, 241, 0.5);\">&#x27;</span> <span title=\"0.185\" style=\"background-color: rgba(229, 227, 240, 0.5);\">eskimo</span> <span title=\"0.188\" style=\"background-color: rgba(228, 227, 239, 0.5);\">&#x27;</span> <span title=\"0.159\" style=\"background-color: rgba(233, 232, 242, 0.5);\">movies</span> <span title=\"0.108\" style=\"background-color: rgba(240, 239, 246, 0.5);\">.</span> <span title=\"0.080\" style=\"background-color: rgba(243, 242, 247, 0.5);\">xxmaj</span> <span title=\"0.066\" style=\"background-color: rgba(245, 243, 248, 0.5);\">how</span> <span title=\"0.057\" style=\"background-color: rgba(246, 244, 249, 0.5);\">wrong</span> <span title=\"0.073\" style=\"background-color: rgba(244, 243, 248, 0.5);\">!</span> <span title=\"0.090\" style=\"background-color: rgba(242, 240, 247, 0.5);\">xxmaj</span> <span title=\"0.107\" style=\"background-color: rgba(240, 239, 246, 0.5);\">as</span> <span title=\"0.119\" style=\"background-color: rgba(239, 237, 245, 0.5);\">an</span> <span title=\"0.115\" style=\"background-color: rgba(240, 238, 245, 0.5);\">avid</span> <span title=\"0.087\" style=\"background-color: rgba(243, 241, 247, 0.5);\">sea</span> <span title=\"0.058\" style=\"background-color: rgba(246, 244, 249, 0.5);\">-</span> <span title=\"0.054\" style=\"background-color: rgba(246, 245, 249, 0.5);\">xxunk</span> <span title=\"0.038\" style=\"background-color: rgba(248, 247, 250, 0.5);\">i</span> <span title=\"0.027\" style=\"background-color: rgba(249, 248, 251, 0.5);\">stayed</span> <span title=\"0.029\" style=\"background-color: rgba(249, 247, 251, 0.5);\">up</span> <span title=\"0.031\" style=\"background-color: rgba(249, 247, 251, 0.5);\">till</span> <span title=\"0.033\" style=\"background-color: rgba(248, 247, 250, 0.5);\">xxunk</span> <span title=\"0.037\" style=\"background-color: rgba(248, 247, 250, 0.5);\">to</span> <span title=\"0.047\" style=\"background-color: rgba(247, 245, 249, 0.5);\">watch</span> <span title=\"0.060\" style=\"background-color: rgba(245, 244, 249, 0.5);\">this</span> <span title=\"0.075\" style=\"background-color: rgba(244, 242, 248, 0.5);\">hoping</span> <span title=\"0.088\" style=\"background-color: rgba(243, 241, 247, 0.5);\">to</span> <span title=\"0.095\" style=\"background-color: rgba(242, 240, 246, 0.5);\">get</span> <span title=\"0.086\" style=\"background-color: rgba(243, 241, 247, 0.5);\">a</span> <span title=\"0.058\" style=\"background-color: rgba(246, 244, 249, 0.5);\">glimpse</span> <span title=\"0.035\" style=\"background-color: rgba(248, 247, 250, 0.5);\">of</span> <span title=\"0.035\" style=\"background-color: rgba(248, 247, 250, 0.5);\">some</span> <span title=\"0.034\" style=\"background-color: rgba(248, 247, 250, 0.5);\">hand</span> <span title=\"0.032\" style=\"background-color: rgba(248, 247, 250, 0.5);\">-</span> <span title=\"0.025\" style=\"background-color: rgba(249, 248, 251, 0.5);\">made</span> <span title=\"0.018\" style=\"background-color: rgba(250, 249, 251, 0.5);\">&#x27;</span> <span title=\"0.018\" style=\"background-color: rgba(250, 249, 251, 0.5);\">skin</span> <span title=\"0.019\" style=\"background-color: rgba(250, 249, 251, 0.5);\">-</span> <span title=\"0.020\" style=\"background-color: rgba(249, 248, 251, 0.5);\">xxunk</span> <span title=\"0.023\" style=\"background-color: rgba(249, 248, 251, 0.5);\">&#x27;</span> <span title=\"0.027\" style=\"background-color: rgba(249, 248, 251, 0.5);\">.</span> <span title=\"0.033\" style=\"background-color: rgba(248, 247, 250, 0.5);\">xxmaj</span> <span title=\"0.043\" style=\"background-color: rgba(247, 246, 250, 0.5);\">the</span> <span title=\"0.054\" style=\"background-color: rgba(246, 245, 249, 0.5);\">movie</span> <span title=\"0.066\" style=\"background-color: rgba(245, 243, 248, 0.5);\">did</span> <span title=\"0.077\" style=\"background-color: rgba(244, 242, 248, 0.5);\">not</span> <span title=\"0.084\" style=\"background-color: rgba(243, 241, 247, 0.5);\">let</span> <span title=\"0.081\" style=\"background-color: rgba(243, 242, 247, 0.5);\">me</span> <span title=\"0.066\" style=\"background-color: rgba(245, 243, 248, 0.5);\">down</span> <span title=\"0.071\" style=\"background-color: rgba(244, 243, 248, 0.5);\">.</span> <span title=\"0.087\" style=\"background-color: rgba(243, 241, 247, 0.5);\">xxmaj</span> <span title=\"0.102\" style=\"background-color: rgba(241, 239, 246, 0.5);\">any</span> <span title=\"0.108\" style=\"background-color: rgba(240, 239, 246, 0.5);\">student</span> <span title=\"0.100\" style=\"background-color: rgba(241, 240, 246, 0.5);\">of</span> <span title=\"0.095\" style=\"background-color: rgba(242, 240, 246, 0.5);\">xxunk</span> <span title=\"0.094\" style=\"background-color: rgba(242, 240, 246, 0.5);\">/</span> <span title=\"0.069\" style=\"background-color: rgba(245, 243, 248, 0.5);\">xxunk</span> <span title=\"0.041\" style=\"background-color: rgba(247, 246, 250, 0.5);\">construction</span> <span title=\"0.052\" style=\"background-color: rgba(246, 245, 249, 0.5);\">should</span> <span title=\"0.065\" style=\"background-color: rgba(245, 243, 248, 0.5);\">have</span> <span title=\"0.080\" style=\"background-color: rgba(243, 242, 247, 0.5);\">a</span> <span title=\"0.096\" style=\"background-color: rgba(242, 240, 246, 0.5);\">look</span> <span title=\"0.108\" style=\"background-color: rgba(240, 239, 246, 0.5);\">-</span> <span title=\"0.104\" style=\"background-color: rgba(241, 239, 246, 0.5);\">see</span> <span title=\"0.074\" style=\"background-color: rgba(244, 243, 248, 0.5);\">here</span> <span title=\"0.038\" style=\"background-color: rgba(248, 247, 250, 0.5);\">.</span> <span title=\"0.043\" style=\"background-color: rgba(247, 246, 250, 0.5);\">(</span> <span title=\"0.050\" style=\"background-color: rgba(247, 245, 249, 0.5);\">xxmaj</span> <span title=\"0.060\" style=\"background-color: rgba(245, 244, 249, 0.5);\">note</span> <span title=\"0.075\" style=\"background-color: rgba(244, 242, 248, 0.5);\">to</span> <span title=\"0.099\" style=\"background-color: rgba(241, 240, 246, 0.5);\">fellow</span> <span title=\"0.130\" style=\"background-color: rgba(238, 236, 244, 0.5);\">xxunk</span> <span title=\"0.165\" style=\"background-color: rgba(232, 230, 241, 0.5);\">:</span> <span title=\"0.198\" style=\"background-color: rgba(227, 226, 239, 0.5);\">they</span> <span title=\"0.212\" style=\"background-color: rgba(224, 223, 238, 0.5);\">appear</span> <span title=\"0.197\" style=\"background-color: rgba(227, 226, 239, 0.5);\">to</span> <span title=\"0.159\" style=\"background-color: rgba(233, 232, 242, 0.5);\">be</span> <span title=\"0.109\" style=\"background-color: rgba(240, 239, 246, 0.5);\">using</span> <span title=\"0.066\" style=\"background-color: rgba(245, 243, 248, 0.5);\">xxmaj</span> <span title=\"0.060\" style=\"background-color: rgba(245, 244, 249, 0.5);\">xxunk</span> <span title=\"0.058\" style=\"background-color: rgba(246, 244, 249, 0.5);\">xxmaj</span> <span title=\"0.063\" style=\"background-color: rgba(245, 243, 248, 0.5);\">sound</span> <span title=\"0.082\" style=\"background-color: rgba(243, 241, 247, 0.5);\">xxunk</span> <span title=\"0.105\" style=\"background-color: rgba(241, 239, 246, 0.5);\">with</span> <span title=\"0.128\" style=\"background-color: rgba(238, 236, 244, 0.5);\">single</span> <span title=\"0.144\" style=\"background-color: rgba(236, 234, 243, 0.5);\">blade</span> <span title=\"0.139\" style=\"background-color: rgba(236, 235, 244, 0.5);\">xxunk</span> <span title=\"0.096\" style=\"background-color: rgba(242, 240, 246, 0.5);\">)</span> <span title=\"0.042\" style=\"background-color: rgba(247, 246, 250, 0.5);\">.</span> <span title=\"0.048\" style=\"background-color: rgba(247, 245, 249, 0.5);\">xxmaj</span> <span title=\"0.057\" style=\"background-color: rgba(246, 244, 249, 0.5);\">but</span> <span title=\"0.069\" style=\"background-color: rgba(245, 243, 248, 0.5);\">the</span> <span title=\"0.085\" style=\"background-color: rgba(243, 241, 247, 0.5);\">film</span> <span title=\"0.098\" style=\"background-color: rgba(241, 240, 246, 0.5);\">went</span> <span title=\"0.106\" style=\"background-color: rgba(240, 239, 246, 0.5);\">way</span> <span title=\"0.103\" style=\"background-color: rgba(241, 239, 246, 0.5);\">beyond</span> <span title=\"0.110\" style=\"background-color: rgba(240, 238, 245, 0.5);\">this</span> <span title=\"0.123\" style=\"background-color: rgba(239, 237, 245, 0.5);\">admittedly</span> <span title=\"0.119\" style=\"background-color: rgba(239, 237, 245, 0.5);\">xxunk</span> <span title=\"0.083\" style=\"background-color: rgba(243, 241, 247, 0.5);\">interest</span> <span title=\"0.044\" style=\"background-color: rgba(247, 246, 250, 0.5);\">.</span> <span title=\"0.058\" style=\"background-color: rgba(246, 244, 249, 0.5);\">xxmaj</span> <span title=\"0.072\" style=\"background-color: rgba(244, 243, 248, 0.5);\">even</span> <span title=\"0.084\" style=\"background-color: rgba(243, 241, 247, 0.5);\">though</span> <span title=\"0.087\" style=\"background-color: rgba(243, 241, 247, 0.5);\">there</span> <span title=\"0.075\" style=\"background-color: rgba(244, 242, 248, 0.5);\">were</span> <span title=\"0.062\" style=\"background-color: rgba(245, 244, 249, 0.5);\">as</span> <span title=\"0.073\" style=\"background-color: rgba(244, 243, 248, 0.5);\">others</span> <span title=\"0.080\" style=\"background-color: rgba(243, 242, 247, 0.5);\">have</span> <span title=\"0.079\" style=\"background-color: rgba(243, 242, 247, 0.5);\">noted</span> <span title=\"0.064\" style=\"background-color: rgba(245, 243, 248, 0.5);\">some</span> <span title=\"0.055\" style=\"background-color: rgba(246, 244, 249, 0.5);\">little</span> <span title=\"0.076\" style=\"background-color: rgba(244, 242, 248, 0.5);\">back</span> <span title=\"0.103\" style=\"background-color: rgba(241, 239, 246, 0.5);\">-</span> <span title=\"0.136\" style=\"background-color: rgba(237, 235, 244, 0.5);\">shot</span> <span title=\"0.173\" style=\"background-color: rgba(231, 229, 241, 0.5);\">-</span> <span title=\"0.213\" style=\"background-color: rgba(224, 223, 238, 0.5);\">xxunk</span> <span title=\"0.243\" style=\"background-color: rgba(219, 219, 235, 0.5);\">-</span> <span title=\"0.243\" style=\"background-color: rgba(219, 219, 235, 0.5);\">bits</span> <span title=\"0.195\" style=\"background-color: rgba(227, 226, 239, 0.5);\">the</span> <span title=\"0.142\" style=\"background-color: rgba(236, 234, 243, 0.5);\">movie</span> <span title=\"0.143\" style=\"background-color: rgba(236, 234, 243, 0.5);\">has</span> <span title=\"0.179\" style=\"background-color: rgba(230, 229, 240, 0.5);\">so</span> <span title=\"0.203\" style=\"background-color: rgba(225, 225, 238, 0.5);\">much</span> <span title=\"0.199\" style=\"background-color: rgba(227, 226, 239, 0.5);\">heart</span> <span title=\"0.138\" style=\"background-color: rgba(236, 235, 244, 0.5);\">they</span> <span title=\"0.046\" style=\"background-color: rgba(247, 246, 250, 0.5);\">are</span> <span title=\"0.042\" style=\"background-color: rgba(247, 246, 250, 0.5);\">just</span> <span title=\"0.048\" style=\"background-color: rgba(247, 245, 249, 0.5);\">a</span> <span title=\"0.052\" style=\"background-color: rgba(246, 245, 249, 0.5);\">minor</span> <span title=\"0.054\" style=\"background-color: rgba(246, 245, 249, 0.5);\">xxunk</span> <span title=\"0.058\" style=\"background-color: rgba(246, 244, 249, 0.5);\">.</span> <span title=\"0.063\" style=\"background-color: rgba(245, 243, 248, 0.5);\">xxmaj</span> <span title=\"0.065\" style=\"background-color: rgba(245, 243, 248, 0.5);\">it</span> <span title=\"0.063\" style=\"background-color: rgba(245, 243, 248, 0.5);\">was</span> <span title=\"0.050\" style=\"background-color: rgba(247, 245, 249, 0.5);\">(</span> <span title=\"0.041\" style=\"background-color: rgba(247, 246, 250, 0.5);\">from</span> <span title=\"0.047\" style=\"background-color: rgba(247, 245, 249, 0.5);\">this</span> <span title=\"0.050\" style=\"background-color: rgba(247, 245, 249, 0.5);\">very</span> <span title=\"0.047\" style=\"background-color: rgba(247, 245, 249, 0.5);\">amateur</span> <span title=\"0.049\" style=\"background-color: rgba(247, 245, 249, 0.5);\">xxunk</span> <span title=\"0.063\" style=\"background-color: rgba(245, 243, 248, 0.5);\">&#x27;s</span> <span title=\"0.081\" style=\"background-color: rgba(243, 242, 247, 0.5);\">viewpoint</span> <span title=\"0.101\" style=\"background-color: rgba(241, 240, 246, 0.5);\">)</span> <span title=\"0.117\" style=\"background-color: rgba(240, 238, 245, 0.5);\">probably</span> <span title=\"0.120\" style=\"background-color: rgba(239, 237, 245, 0.5);\">the</span> <span title=\"0.103\" style=\"background-color: rgba(241, 239, 246, 0.5);\">perfect</span> <span title=\"0.086\" style=\"background-color: rgba(243, 241, 247, 0.5);\">time</span> <span title=\"0.078\" style=\"background-color: rgba(244, 242, 248, 0.5);\">to</span> <span title=\"0.066\" style=\"background-color: rgba(245, 243, 248, 0.5);\">make</span> <span title=\"0.066\" style=\"background-color: rgba(245, 243, 248, 0.5);\">this</span> <span title=\"0.065\" style=\"background-color: rgba(245, 243, 248, 0.5);\">movie</span> <span title=\"0.064\" style=\"background-color: rgba(245, 243, 248, 0.5);\">.</span> <span title=\"0.046\" style=\"background-color: rgba(247, 246, 250, 0.5);\">xxmaj</span> <span title=\"0.021\" style=\"background-color: rgba(249, 248, 251, 0.5);\">early</span> <span title=\"0.022\" style=\"background-color: rgba(249, 248, 251, 0.5);\">thirties</span> <span title=\"0.025\" style=\"background-color: rgba(249, 248, 251, 0.5);\">:</span> <span title=\"0.030\" style=\"background-color: rgba(249, 247, 251, 0.5);\">the</span> <span title=\"0.037\" style=\"background-color: rgba(248, 247, 250, 0.5);\">&#x27;</span> <span title=\"0.047\" style=\"background-color: rgba(247, 245, 249, 0.5);\">xxunk</span> <span title=\"0.059\" style=\"background-color: rgba(245, 244, 249, 0.5);\">&#x27;</span> <span title=\"0.072\" style=\"background-color: rgba(244, 243, 248, 0.5);\">are</span> <span title=\"0.081\" style=\"background-color: rgba(243, 242, 247, 0.5);\">so</span> <span title=\"0.080\" style=\"background-color: rgba(243, 242, 247, 0.5);\">new</span> <span title=\"0.062\" style=\"background-color: rgba(245, 244, 249, 0.5);\">that</span> <span title=\"0.045\" style=\"background-color: rgba(247, 246, 250, 0.5);\">they</span> <span title=\"0.041\" style=\"background-color: rgba(247, 246, 250, 0.5);\">(</span> <span title=\"0.035\" style=\"background-color: rgba(248, 247, 250, 0.5);\">including</span> <span title=\"0.030\" style=\"background-color: rgba(249, 247, 251, 0.5);\">xxmaj</span> <span title=\"0.024\" style=\"background-color: rgba(249, 248, 251, 0.5);\">xxunk</span> <span title=\"0.022\" style=\"background-color: rgba(249, 248, 251, 0.5);\">xxup</span> <span title=\"0.024\" style=\"background-color: rgba(249, 248, 251, 0.5);\">b.</span> <span title=\"0.027\" style=\"background-color: rgba(249, 248, 251, 0.5);\">xxmaj</span> <span title=\"0.030\" style=\"background-color: rgba(249, 247, 251, 0.5);\">xxunk</span> <span title=\"0.036\" style=\"background-color: rgba(248, 247, 250, 0.5);\">!</span> <span title=\"0.042\" style=\"background-color: rgba(247, 246, 250, 0.5);\">)</span> <span title=\"0.049\" style=\"background-color: rgba(247, 245, 249, 0.5);\">actually</span> <span title=\"0.056\" style=\"background-color: rgba(246, 244, 249, 0.5);\">let</span> <span title=\"0.060\" style=\"background-color: rgba(245, 244, 249, 0.5);\">the</span> <span title=\"0.057\" style=\"background-color: rgba(246, 244, 249, 0.5);\">xxmaj</span> <span title=\"0.060\" style=\"background-color: rgba(245, 244, 249, 0.5);\">xxunk</span> <span title=\"0.077\" style=\"background-color: rgba(244, 242, 248, 0.5);\">speak</span> <span title=\"0.097\" style=\"background-color: rgba(242, 240, 246, 0.5);\">in</span> <span title=\"0.116\" style=\"background-color: rgba(240, 238, 245, 0.5);\">their</span> <span title=\"0.131\" style=\"background-color: rgba(238, 236, 244, 0.5);\">own</span> <span title=\"0.141\" style=\"background-color: rgba(236, 234, 243, 0.5);\">tongue</span> <span title=\"0.144\" style=\"background-color: rgba(236, 234, 243, 0.5);\">.</span> <span title=\"0.138\" style=\"background-color: rgba(236, 235, 244, 0.5);\">xxmaj</span> <span title=\"0.093\" style=\"background-color: rgba(242, 240, 247, 0.5);\">and</span> <span title=\"0.020\" style=\"background-color: rgba(249, 248, 251, 0.5);\">there</span> <span title=\"0.021\" style=\"background-color: rgba(249, 248, 251, 0.5);\">is</span> <span title=\"0.022\" style=\"background-color: rgba(249, 248, 251, 0.5);\">so</span> <span title=\"0.025\" style=\"background-color: rgba(249, 248, 251, 0.5);\">much</span> <span title=\"0.027\" style=\"background-color: rgba(249, 248, 251, 0.5);\">that</span> <span title=\"0.029\" style=\"background-color: rgba(249, 247, 251, 0.5);\">was</span> <span title=\"0.031\" style=\"background-color: rgba(249, 247, 251, 0.5);\">still</span> <span title=\"0.035\" style=\"background-color: rgba(248, 247, 250, 0.5);\">,</span> <span title=\"0.043\" style=\"background-color: rgba(247, 246, 250, 0.5);\">despite</span> <span title=\"0.053\" style=\"background-color: rgba(246, 245, 249, 0.5);\">the</span> <span title=\"0.066\" style=\"background-color: rgba(245, 243, 248, 0.5);\">infused</span> <span title=\"0.082\" style=\"background-color: rgba(243, 242, 247, 0.5);\">melodrama</span> <span title=\"0.100\" style=\"background-color: rgba(241, 240, 246, 0.5);\">,</span> <span title=\"0.117\" style=\"background-color: rgba(240, 238, 245, 0.5);\">authentic</span> <span title=\"0.117\" style=\"background-color: rgba(240, 238, 245, 0.5);\">.</span> <span title=\"0.086\" style=\"background-color: rgba(243, 241, 247, 0.5);\">xxmaj</span> <span title=\"0.048\" style=\"background-color: rgba(247, 245, 249, 0.5);\">they</span> <span title=\"0.041\" style=\"background-color: rgba(247, 246, 250, 0.5);\">are</span> <span title=\"0.038\" style=\"background-color: rgba(248, 247, 250, 0.5);\">really</span> <span title=\"0.049\" style=\"background-color: rgba(247, 245, 249, 0.5);\">xxunk</span> <span title=\"0.065\" style=\"background-color: rgba(245, 243, 248, 0.5);\">that</span> <span title=\"0.084\" style=\"background-color: rgba(243, 241, 247, 0.5);\">polar</span> <span title=\"0.104\" style=\"background-color: rgba(241, 239, 246, 0.5);\">bear</span> <span title=\"0.119\" style=\"background-color: rgba(239, 237, 245, 0.5);\">,</span> <span title=\"0.121\" style=\"background-color: rgba(239, 237, 245, 0.5);\">that</span> <span title=\"0.098\" style=\"background-color: rgba(241, 240, 246, 0.5);\">whale</span> <span title=\"0.056\" style=\"background-color: rgba(246, 244, 249, 0.5);\">and</span> <span title=\"0.029\" style=\"background-color: rgba(249, 247, 251, 0.5);\">those</span> <span title=\"0.033\" style=\"background-color: rgba(248, 247, 250, 0.5);\">xxunk</span> <span title=\"0.037\" style=\"background-color: rgba(248, 247, 250, 0.5);\">.</span> <span title=\"0.040\" style=\"background-color: rgba(247, 246, 250, 0.5);\">a</span> <span title=\"0.040\" style=\"background-color: rgba(247, 246, 250, 0.5);\">xxunk</span> <span title=\"0.037\" style=\"background-color: rgba(248, 247, 250, 0.5);\">version</span> <span title=\"0.038\" style=\"background-color: rgba(248, 247, 250, 0.5);\">of</span> <span title=\"0.047\" style=\"background-color: rgba(247, 245, 249, 0.5);\">this</span> <span title=\"0.060\" style=\"background-color: rgba(245, 244, 249, 0.5);\">film</span> <span title=\"0.075\" style=\"background-color: rgba(244, 242, 248, 0.5);\">would</span> <span title=\"0.091\" style=\"background-color: rgba(242, 240, 247, 0.5);\">have</span> <span title=\"0.103\" style=\"background-color: rgba(241, 239, 246, 0.5);\">been</span> <span title=\"0.106\" style=\"background-color: rgba(240, 239, 246, 0.5);\">so</span> <span title=\"0.090\" style=\"background-color: rgba(242, 240, 247, 0.5);\">cheesy</span> <span title=\"0.057\" style=\"background-color: rgba(246, 244, 249, 0.5);\">with</span> <span title=\"0.035\" style=\"background-color: rgba(248, 247, 250, 0.5);\">&#x27;</span> <span title=\"0.034\" style=\"background-color: rgba(248, 247, 250, 0.5);\">stars</span> <span title=\"0.033\" style=\"background-color: rgba(248, 247, 250, 0.5);\">&#x27;</span> <span title=\"0.032\" style=\"background-color: rgba(248, 247, 250, 0.5);\">,</span> <span title=\"0.025\" style=\"background-color: rgba(249, 248, 251, 0.5);\">xxmaj</span> <span title=\"0.023\" style=\"background-color: rgba(249, 248, 251, 0.5);\">technicolor</span> <span title=\"0.025\" style=\"background-color: rgba(249, 248, 251, 0.5);\">,</span> <span title=\"0.028\" style=\"background-color: rgba(249, 247, 251, 0.5);\">etc</span> <span title=\"0.032\" style=\"background-color: rgba(248, 247, 250, 0.5);\">.</span> <span title=\"0.035\" style=\"background-color: rgba(248, 247, 250, 0.5);\">to</span> <span title=\"0.037\" style=\"background-color: rgba(248, 247, 250, 0.5);\">xxunk</span> <span title=\"0.038\" style=\"background-color: rgba(248, 247, 250, 0.5);\">it</span> <span title=\"0.036\" style=\"background-color: rgba(248, 247, 250, 0.5);\">up</span> <span title=\"0.036\" style=\"background-color: rgba(248, 247, 250, 0.5);\">.</span> <span title=\"0.044\" style=\"background-color: rgba(247, 246, 250, 0.5);\">xxmaj</span> <span title=\"0.054\" style=\"background-color: rgba(246, 245, 249, 0.5);\">the</span> <span title=\"0.065\" style=\"background-color: rgba(245, 243, 248, 0.5);\">seventies</span> <span title=\"0.075\" style=\"background-color: rgba(244, 242, 248, 0.5);\">version</span> <span title=\"0.075\" style=\"background-color: rgba(244, 242, 248, 0.5);\">?</span> <span title=\"0.063\" style=\"background-color: rgba(245, 243, 248, 0.5);\">xxmaj</span> <span title=\"0.052\" style=\"background-color: rgba(246, 245, 249, 0.5);\">do</span> <span title=\"0.057\" style=\"background-color: rgba(246, 244, 249, 0.5);\">n&#x27;t</span> <span title=\"0.068\" style=\"background-color: rgba(245, 243, 248, 0.5);\">even</span> <span title=\"0.088\" style=\"background-color: rgba(243, 241, 247, 0.5);\">.</span> <span title=\"0.110\" style=\"background-color: rgba(240, 238, 245, 0.5);\">a</span> <span title=\"0.130\" style=\"background-color: rgba(238, 236, 244, 0.5);\">very</span> <span title=\"0.148\" style=\"background-color: rgba(235, 233, 243, 0.5);\">good</span> <span title=\"0.150\" style=\"background-color: rgba(234, 233, 243, 0.5);\">companion</span> <span title=\"0.115\" style=\"background-color: rgba(240, 238, 245, 0.5);\">piece</span> <span title=\"0.060\" style=\"background-color: rgba(245, 244, 249, 0.5);\">to</span> <span title=\"0.059\" style=\"background-color: rgba(245, 244, 249, 0.5);\">this</span> <span title=\"0.072\" style=\"background-color: rgba(244, 243, 248, 0.5);\">excellent</span> <span title=\"0.083\" style=\"background-color: rgba(243, 241, 247, 0.5);\">movie</span> <span title=\"0.087\" style=\"background-color: rgba(243, 241, 247, 0.5);\">is</span> <span title=\"0.076\" style=\"background-color: rgba(244, 242, 248, 0.5);\">&quot;</span> <span title=\"0.054\" style=\"background-color: rgba(246, 245, 249, 0.5);\">xxmaj</span> <span title=\"0.038\" style=\"background-color: rgba(248, 247, 250, 0.5);\">white</span> <span title=\"0.026\" style=\"background-color: rgba(249, 248, 251, 0.5);\">shadows</span> <span title=\"0.030\" style=\"background-color: rgba(249, 247, 251, 0.5);\">in</span> <span title=\"0.035\" style=\"background-color: rgba(248, 247, 250, 0.5);\">the</span> <span title=\"0.041\" style=\"background-color: rgba(247, 246, 250, 0.5);\">south</span> <span title=\"0.047\" style=\"background-color: rgba(247, 245, 249, 0.5);\">xxunk</span> <span title=\"0.053\" style=\"background-color: rgba(246, 245, 249, 0.5);\">&quot;</span> <span title=\"0.061\" style=\"background-color: rgba(245, 244, 249, 0.5);\">(</span> <span title=\"0.071\" style=\"background-color: rgba(244, 243, 248, 0.5);\">xxunk</span> <span title=\"0.078\" style=\"background-color: rgba(244, 242, 248, 0.5);\">)</span> <span title=\"0.084\" style=\"background-color: rgba(243, 241, 247, 0.5);\">xxmaj</span> <span title=\"0.099\" style=\"background-color: rgba(241, 240, 246, 0.5);\">xxunk</span> <span title=\"0.117\" style=\"background-color: rgba(240, 238, 245, 0.5);\">the</span> <span title=\"0.141\" style=\"background-color: rgba(236, 234, 243, 0.5);\">mirror</span> <span title=\"0.161\" style=\"background-color: rgba(232, 231, 242, 0.5);\">image</span> <span title=\"0.160\" style=\"background-color: rgba(233, 232, 242, 0.5);\">to</span> <span title=\"0.114\" style=\"background-color: rgba(240, 238, 245, 0.5);\">&quot;</span> <span title=\"0.047\" style=\"background-color: rgba(247, 246, 250, 0.5);\">xxmaj</span> <span title=\"0.061\" style=\"background-color: rgba(245, 244, 249, 0.5);\">eskimo</span> <span title=\"0.078\" style=\"background-color: rgba(244, 242, 248, 0.5);\">&quot;</span> <span title=\"0.096\" style=\"background-color: rgba(242, 240, 246, 0.5);\">it</span> <span title=\"0.113\" style=\"background-color: rgba(240, 238, 245, 0.5);\">also</span> <span title=\"0.121\" style=\"background-color: rgba(239, 237, 245, 0.5);\">deals</span> <span title=\"0.118\" style=\"background-color: rgba(239, 237, 245, 0.5);\">with</span> <span title=\"0.111\" style=\"background-color: rgba(240, 238, 245, 0.5);\">the</span> <span title=\"0.090\" style=\"background-color: rgba(242, 240, 247, 0.5);\">relentless</span> <span title=\"0.062\" style=\"background-color: rgba(245, 244, 249, 0.5);\">and</span> <span title=\"0.046\" style=\"background-color: rgba(247, 246, 250, 0.5);\">profound</span> <span title=\"0.054\" style=\"background-color: rgba(246, 245, 249, 0.5);\">xxunk</span> <span title=\"0.071\" style=\"background-color: rgba(244, 243, 248, 0.5);\">of</span> <span title=\"0.101\" style=\"background-color: rgba(241, 240, 246, 0.5);\">xxmaj</span> <span title=\"0.145\" style=\"background-color: rgba(235, 233, 243, 0.5);\">western</span> <span title=\"0.205\" style=\"background-color: rgba(225, 225, 238, 0.5);\">culture</span> <span title=\"0.288\" style=\"background-color: rgba(209, 209, 230, 0.5);\">/</span> <span title=\"0.399\" style=\"background-color: rgba(182, 182, 216, 0.5);\">technology</span> <span title=\"0.538\" style=\"background-color: rgba(149, 145, 195, 0.5);\">on</span> <span title=\"0.703\" style=\"background-color: rgba(114, 97, 171, 0.5);\">an</span> <span title=\"0.871\" style=\"background-color: rgba(84, 39, 143, 0.5);\">xxunk</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">people</span> <span title=\"0.975\" style=\"background-color: rgba(66, 7, 128, 0.5);\">.</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "txt_ci = TextClassificationInterpretation.from_learner(learn)\n",
    "test_text = data.train_dl.x[0].text[6:] # .text object adds `xxbos`, remove for txt_ci\n",
    "txt_ci.show_intrinsic_attention(test_text,cmap=cm.Purples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also view the raw attention values with `.intrinsic_attention(text)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4254, 0.1558, 0.0886, 0.0547, 0.0469, 0.0471, 0.0572, 0.0728, 0.0888,\n",
       "        0.1000, 0.0968, 0.0684, 0.0376, 0.0455, 0.0540, 0.0614, 0.0662, 0.0724,\n",
       "        0.0862, 0.1099, 0.1381, 0.1658, 0.1851, 0.1885, 0.1594, 0.1082, 0.0797,\n",
       "        0.0661, 0.0569, 0.0726, 0.0903, 0.1071, 0.1189, 0.1154, 0.0873, 0.0584,\n",
       "        0.0536, 0.0378, 0.0266, 0.0290, 0.0310, 0.0330, 0.0371, 0.0472, 0.0601,\n",
       "        0.0747, 0.0878, 0.0947, 0.0859, 0.0577, 0.0350, 0.0354, 0.0344, 0.0324,\n",
       "        0.0254, 0.0182, 0.0183, 0.0188, 0.0202, 0.0226, 0.0268, 0.0334, 0.0426,\n",
       "        0.0536, 0.0661, 0.0771, 0.0838, 0.0808, 0.0659, 0.0705, 0.0875, 0.1024,\n",
       "        0.1084, 0.1001, 0.0952, 0.0945, 0.0693, 0.0410, 0.0515, 0.0646, 0.0799,\n",
       "        0.0959, 0.1078, 0.1040, 0.0738, 0.0379, 0.0434, 0.0497, 0.0597, 0.0752,\n",
       "        0.0988, 0.1298, 0.1650, 0.1979, 0.2123, 0.1971, 0.1588, 0.1087, 0.0663,\n",
       "        0.0603, 0.0583, 0.0630, 0.0822, 0.1047, 0.1278, 0.1439, 0.1392, 0.0962,\n",
       "        0.0424, 0.0484, 0.0571, 0.0692, 0.0849, 0.0983, 0.1055, 0.1028, 0.1097,\n",
       "        0.1230, 0.1191, 0.0826, 0.0445, 0.0576, 0.0717, 0.0836, 0.0873, 0.0748,\n",
       "        0.0620, 0.0733, 0.0803, 0.0795, 0.0640, 0.0554, 0.0757, 0.1029, 0.1362,\n",
       "        0.1732, 0.2129, 0.2433, 0.2432, 0.1951, 0.1419, 0.1426, 0.1787, 0.2034,\n",
       "        0.1985, 0.1378, 0.0456, 0.0416, 0.0479, 0.0517, 0.0537, 0.0585, 0.0626,\n",
       "        0.0654, 0.0632, 0.0505, 0.0411, 0.0472, 0.0501, 0.0473, 0.0488, 0.0631,\n",
       "        0.0812, 0.1011, 0.1167, 0.1198, 0.1027, 0.0858, 0.0776, 0.0663, 0.0660,\n",
       "        0.0652, 0.0640, 0.0462, 0.0214, 0.0222, 0.0252, 0.0301, 0.0374, 0.0473,\n",
       "        0.0593, 0.0718, 0.0810, 0.0804, 0.0615, 0.0450, 0.0412, 0.0351, 0.0302,\n",
       "        0.0237, 0.0219, 0.0239, 0.0267, 0.0305, 0.0358, 0.0422, 0.0494, 0.0565,\n",
       "        0.0596, 0.0571, 0.0605, 0.0775, 0.0971, 0.1157, 0.1309, 0.1410, 0.1436,\n",
       "        0.1384, 0.0932, 0.0200, 0.0209, 0.0225, 0.0247, 0.0270, 0.0291, 0.0307,\n",
       "        0.0348, 0.0427, 0.0532, 0.0664, 0.0820, 0.0999, 0.1166, 0.1170, 0.0865,\n",
       "        0.0476, 0.0413, 0.0379, 0.0494, 0.0652, 0.0844, 0.1037, 0.1193, 0.1206,\n",
       "        0.0980, 0.0559, 0.0294, 0.0333, 0.0370, 0.0400, 0.0405, 0.0369, 0.0376,\n",
       "        0.0475, 0.0602, 0.0752, 0.0910, 0.1030, 0.1056, 0.0899, 0.0570, 0.0346,\n",
       "        0.0338, 0.0330, 0.0319, 0.0253, 0.0228, 0.0252, 0.0283, 0.0315, 0.0348,\n",
       "        0.0374, 0.0383, 0.0355, 0.0356, 0.0440, 0.0542, 0.0655, 0.0746, 0.0755,\n",
       "        0.0630, 0.0516, 0.0567, 0.0682, 0.0878, 0.1095, 0.1305, 0.1478, 0.1500,\n",
       "        0.1148, 0.0595, 0.0594, 0.0722, 0.0833, 0.0872, 0.0760, 0.0544, 0.0378,\n",
       "        0.0258, 0.0295, 0.0348, 0.0408, 0.0470, 0.0531, 0.0614, 0.0712, 0.0778,\n",
       "        0.0838, 0.0990, 0.1166, 0.1407, 0.1606, 0.1596, 0.1136, 0.0466, 0.0610,\n",
       "        0.0779, 0.0961, 0.1126, 0.1205, 0.1183, 0.1113, 0.0903, 0.0620, 0.0462,\n",
       "        0.0545, 0.0705, 0.1009, 0.1450, 0.2053, 0.2883, 0.3991, 0.5382, 0.7031,\n",
       "        0.8714, 1.0000, 0.9753, 0.6518], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_ci.intrinsic_attention(test_text)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"RNNLearner.load_encoder\" class=\"doc_header\"><code>load_encoder</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L63\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#RNNLearner-load_encoder-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>load_encoder</code>(**`name`**:`str`, **`device`**:[`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device)=***`None`***)\n",
       "\n",
       "<div class=\"collapse\" id=\"RNNLearner-load_encoder-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#RNNLearner-load_encoder-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>load_encoder</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Load the encoder `name` from the model directory.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(RNNLearner.load_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"RNNLearner.save_encoder\" class=\"doc_header\"><code>save_encoder</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L57\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#RNNLearner-save_encoder-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>save_encoder</code>(**`name`**:`str`)\n",
       "\n",
       "<div class=\"collapse\" id=\"RNNLearner-save_encoder-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#RNNLearner-save_encoder-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>save_encoder</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Save the encoder to `name` inside the model directory.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(RNNLearner.save_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"RNNLearner.load_pretrained\" class=\"doc_header\"><code>load_pretrained</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L72\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#RNNLearner-load_pretrained-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>load_pretrained</code>(**`wgts_fname`**:`str`, **`itos_fname`**:`str`, **`strict`**:`bool`=***`True`***)\n",
       "\n",
       "<div class=\"collapse\" id=\"RNNLearner-load_pretrained-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#RNNLearner-load_pretrained-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>load_pretrained</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Load a pretrained model and adapts it to the data vocabulary.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(RNNLearner.load_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opens the weights in the `wgts_fname` of `self.model_dir` and the dictionary in `itos_fname` then adapts the pretrained weights to the vocabulary of the <code>data</code>. The two files should be in the models directory of the `learner.path`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"convert_weights\" class=\"doc_header\"><code>convert_weights</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L28\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#convert_weights-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>convert_weights</code>(**`wgts`**:`Weights`, **`stoi_wgts`**:`Dict`\\[`str`, `int`\\], **`itos_new`**:`StrList`) → `Weights`\n",
       "\n",
       "<div class=\"collapse\" id=\"convert_weights-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#convert_weights-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>convert_weights</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Convert the model `wgts` to go with a new vocabulary.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(convert_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses the dictionary `stoi_wgts` (mapping of word to id) of the weights to map them to a new dictionary `itos_new` (mapping id to word)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"LanguageLearner\" class=\"doc_header\"><code>class</code> <code>LanguageLearner</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L113\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#LanguageLearner-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n",
       "\n",
       "> <code>LanguageLearner</code>(**`data`**:[`DataBunch`](/basic_data.html#DataBunch), **`model`**:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), **`split_func`**:`OptSplitFunc`=***`None`***, **`clip`**:`float`=***`None`***, **`alpha`**:`float`=***`2.0`***, **`beta`**:`float`=***`1.0`***, **`metrics`**=***`None`***, **\\*\\*`learn_kwargs`**) :: [`RNNLearner`](/text.learner.html#RNNLearner)\n",
       "\n",
       "<div class=\"collapse\" id=\"LanguageLearner-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#LanguageLearner-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>LanguageLearner</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Subclass of RNNLearner for predictions.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LanguageLearner, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LanguageLearner.predict\" class=\"doc_header\"><code>predict</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L116\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#LanguageLearner-predict-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>predict</code>(**`text`**:`str`, **`n_words`**:`int`=***`1`***, **`no_unk`**:`bool`=***`True`***, **`temperature`**:`float`=***`1.0`***, **`min_p`**:`float`=***`None`***, **`sep`**:`str`=***`' '`***, **`decoder`**=***`'decode_spec_tokens'`***)\n",
       "\n",
       "<div class=\"collapse\" id=\"LanguageLearner-predict-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#LanguageLearner-predict-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>predict</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Return the `n_words` that come after `text`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LanguageLearner.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `no_unk=True` the unknown token is never picked. Words are taken randomly with the distribution of probabilities returned by the model. If `min_p` is not `None`, that value is the minimum probability to be considered in the pool of words. Lowering `temperature` will make the texts less randomized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LanguageLearner.beam_search\" class=\"doc_header\"><code>beam_search</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L137\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#LanguageLearner-beam_search-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>beam_search</code>(**`text`**:`str`, **`n_words`**:`int`, **`no_unk`**:`bool`=***`True`***, **`top_k`**:`int`=***`10`***, **`beam_sz`**:`int`=***`1000`***, **`temperature`**:`float`=***`1.0`***, **`sep`**:`str`=***`' '`***, **`decoder`**=***`'decode_spec_tokens'`***)\n",
       "\n",
       "<div class=\"collapse\" id=\"LanguageLearner-beam_search-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#LanguageLearner-beam_search-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>beam_search</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Return the `n_words` that come after `text` using beam search.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LanguageLearner.beam_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic functions to get a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"get_language_model\" class=\"doc_header\"><code>get_language_model</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L187\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#get_language_model-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>get_language_model</code>(**`arch`**:`Callable`, **`vocab_sz`**:`int`, **`config`**:`dict`=***`None`***, **`drop_mult`**:`float`=***`1.0`***)\n",
       "\n",
       "<div class=\"collapse\" id=\"get_language_model-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#get_language_model-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>get_language_model</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Create a language model from `arch` and its `config`, maybe `pretrained`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(get_language_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"get_text_classifier\" class=\"doc_header\"><code>get_text_classifier</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L269\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#get_text_classifier-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>get_text_classifier</code>(**`arch`**:`Callable`, **`vocab_sz`**:`int`, **`n_class`**:`int`, **`bptt`**:`int`=***`70`***, **`max_len`**:`int`=***`1400`***, **`config`**:`dict`=***`None`***, **`drop_mult`**:`float`=***`1.0`***, **`lin_ftrs`**:`Collection`\\[`int`\\]=***`None`***, **`ps`**:`Collection`\\[`float`\\]=***`None`***, **`pad_idx`**:`int`=***`1`***) → [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n",
       "\n",
       "<div class=\"collapse\" id=\"get_text_classifier-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#get_text_classifier-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>get_text_classifier</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Create a text classifier from `arch` and its `config`, maybe `pretrained`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(get_text_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses an encoder taken from the `arch` on `config`. This encoder is fed the sequence by successive bits of size `bptt` and we only keep the last `max_seq` outputs for the pooling layers.\n",
    "\n",
    "The decoder use a concatenation of the last outputs, a `MaxPooling` of all the outputs and an `AveragePooling` of all the outputs. It then uses a list of `BatchNorm`, `Dropout`, `Linear`, `ReLU` blocks (with no `ReLU` in the last one), using a first layer size of `3*emb_sz` then following the numbers in `n_layers`. The dropouts probabilities are read in `drops`.\n",
    "\n",
    "Note that the model returns a list of three things, the actual output being the first, the two others being the intermediate hidden states before and after dropout (used by the [`RNNTrainer`](/callbacks.rnn.html#RNNTrainer)). Most loss functions expect one output, so you should use a Callback to remove the other two if you're not using [`RNNTrainer`](/callbacks.rnn.html#RNNTrainer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undocumented Methods - Methods moved below this line will intentionally be hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Methods - Please document or move to the undocumented section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"MultiBatchEncoder.forward\" class=\"doc_header\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L257\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#MultiBatchEncoder-forward-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>forward</code>(**`input`**:`LongTensor`) → `Tuple`\\[`Tensor`, `Tensor`\\]\n",
       "\n",
       "<div class=\"collapse\" id=\"MultiBatchEncoder-forward-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#MultiBatchEncoder-forward-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>forward</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Defines the computation performed at every call. Should be overridden by all subclasses.\n",
       "\n",
       ".. note::\n",
       "    Although the recipe for forward pass needs to be defined within\n",
       "    this function, one should call the :class:`Module` instance afterwards\n",
       "    instead of this since the former takes care of running the\n",
       "    registered hooks while the latter silently ignores them. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(MultiBatchEncoder.forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LanguageLearner.show_results\" class=\"doc_header\"><code>show_results</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L165\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#LanguageLearner-show_results-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>show_results</code>(**`ds_type`**=***`<DatasetType.Valid: 2>`***, **`rows`**:`int`=***`5`***, **`max_len`**:`int`=***`20`***)\n",
       "\n",
       "<div class=\"collapse\" id=\"LanguageLearner-show_results-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#LanguageLearner-show_results-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>show_results</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Show `rows` result of predictions on `ds_type` dataset.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LanguageLearner.show_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"MultiBatchEncoder.concat\" class=\"doc_header\"><code>concat</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L250\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#MultiBatchEncoder-concat-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>concat</code>(**`arrs`**:`Collection`\\[`Tensor`\\]) → `Tensor`\n",
       "\n",
       "<div class=\"collapse\" id=\"MultiBatchEncoder-concat-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#MultiBatchEncoder-concat-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>concat</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Concatenate the `arrs` along the batch dimension.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(MultiBatchEncoder.concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"MultiBatchEncoder\" class=\"doc_header\"><code>class</code> <code>MultiBatchEncoder</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L244\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#MultiBatchEncoder-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h2>\n",
       "\n",
       "> <code>MultiBatchEncoder</code>(**`bptt`**:`int`, **`max_len`**:`int`, **`module`**:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), **`pad_idx`**:`int`=***`1`***) :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n",
       "\n",
       "<div class=\"collapse\" id=\"MultiBatchEncoder-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#MultiBatchEncoder-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>MultiBatchEncoder</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n",
       "\n",
       "Create an encoder over `module` that can process a full sentence.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(MultiBatchEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"decode_spec_tokens\" class=\"doc_header\"><code>decode_spec_tokens</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L94\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#decode_spec_tokens-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>decode_spec_tokens</code>(**`tokens`**)\n",
       "\n",
       "<div class=\"collapse\" id=\"decode_spec_tokens-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#decode_spec_tokens-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>decode_spec_tokens</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(decode_spec_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"MultiBatchEncoder.reset\" class=\"doc_header\"><code>reset</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L254\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#MultiBatchEncoder-reset-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n",
       "\n",
       "> <code>reset</code>()\n",
       "\n",
       "<div class=\"collapse\" id=\"MultiBatchEncoder-reset-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#MultiBatchEncoder-reset-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>reset</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(MultiBatchEncoder.reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jekyll": {
   "keywords": "fastai",
   "summary": "Easy access of language models and ULMFiT",
   "title": "text.learner"
  },
  "kernelspec": {
   "display_name": "Python 3.7 fasta.ai1 DEV",
   "language": "python",
   "name": "fastai1_dev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
